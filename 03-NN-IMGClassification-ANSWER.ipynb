{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Image Classification using Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size = 100\n",
    "learning_rate = 0.003\n",
    "training_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_DATA\\train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_DATA\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_DATA\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_DATA\\t10k-labels-idx1-ubyte.gz\n",
      "# of Train Data:  55000\n",
      "# of Test Data:  10000\n",
      "# of Validation Data:  5000\n"
     ]
    }
   ],
   "source": [
    "# MNIST data set\n",
    "mnist = input_data.read_data_sets(\"./MNIST_DATA\", one_hot=True)\n",
    "\n",
    "print(\"# of Train Data: \", mnist.train.num_examples)\n",
    "print(\"# of Test Data: \", mnist.test.num_examples)\n",
    "print(\"# of Validation Data: \", mnist.validation.num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 784), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Network Layers\n",
    "L = 200\n",
    "M = 100\n",
    "N = 60\n",
    "O = 30\n",
    "\n",
    "# input\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "XX = tf.reshape(X, [-1, 784])\n",
    "\n",
    "print(X)\n",
    "print(Y_)\n",
    "print(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer1 (L=200)\n",
    "W1 = tf.Variable(tf.truncated_normal([784, L], stddev=0.1))\n",
    "B1 = tf.Variable(tf.zeros([L]))\n",
    "Y1 = tf.nn.sigmoid(tf.matmul(XX, W1) + B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer2 (M=100)\n",
    "W2 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))\n",
    "B2 = tf.Variable(tf.zeros([M]))\n",
    "Y2 = tf.nn.sigmoid(tf.matmul(Y1, W2) + B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer3 (N=60)\n",
    "W3 = tf.Variable(tf.truncated_normal([M, N], stddev=0.1))\n",
    "B3 = tf.Variable(tf.zeros([N]))\n",
    "Y3 = tf.nn.sigmoid(tf.matmul(Y2, W3) + B3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer4 (O=30)\n",
    "W4 = tf.Variable(tf.truncated_normal([N, O], stddev=0.1))\n",
    "B4 = tf.Variable(tf.zeros([O]))\n",
    "Y4 = tf.nn.sigmoid(tf.matmul(Y3, W4) + B4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Layer (Y=10)\n",
    "W5 = tf.Variable(tf.truncated_normal([O, 10], stddev=0.1))\n",
    "B5 = tf.Variable(tf.zeros([10]))\n",
    "Ylogits = tf.matmul(Y4, W5) + B5\n",
    "Y = tf.nn.softmax(Ylogits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function (Cross Entropy)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=Ylogits, labels=Y_)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)*100\n",
    "\n",
    "# Optimize (Adam)\n",
    "train_step = tf.train.AdamOptimizer(\n",
    "                learning_rate).minimize(cross_entropy)\n",
    "# train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(\n",
    "                tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 \tAccuracy:  0.91\n",
      "Epoch:  1 \tAccuracy:  0.95\n",
      "Epoch:  2 \tAccuracy:  0.94\n",
      "Epoch:  3 \tAccuracy:  0.97\n",
      "Epoch:  4 \tAccuracy:  1.0\n",
      "Epoch:  5 \tAccuracy:  0.97\n",
      "Epoch:  6 \tAccuracy:  0.99\n",
      "Epoch:  7 \tAccuracy:  1.0\n",
      "Epoch:  8 \tAccuracy:  1.0\n",
      "Epoch:  9 \tAccuracy:  0.99\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train\n",
    "for epoch in range(training_epochs):\n",
    "    batch_count = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(batch_count):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, acc = sess.run([train_step, accuracy], \n",
    "                             feed_dict={X: batch_x,\n",
    "                                        Y_: batch_y})\n",
    "    print(\"Epoch: \", epoch, \"\\tAccuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9717\n",
      "done\n",
      "Wall time: 140 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test accuracy\n",
    "print(\"Test Accuracy: \", sess.run(accuracy,\n",
    "                            feed_dict={X: mnist.test.images,\n",
    "                                       Y_: mnist.test.labels}))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_DATA\\train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_DATA\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_DATA\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_DATA\\t10k-labels-idx1-ubyte.gz\n",
      "Epoch:  0 \tAccuracy:  0.96\n",
      "Epoch:  1 \tAccuracy:  0.96\n",
      "Epoch:  2 \tAccuracy:  0.99\n",
      "Epoch:  3 \tAccuracy:  0.99\n",
      "Epoch:  4 \tAccuracy:  1.0\n",
      "Epoch:  5 \tAccuracy:  0.98\n",
      "Epoch:  6 \tAccuracy:  0.99\n",
      "Epoch:  7 \tAccuracy:  1.0\n",
      "Epoch:  8 \tAccuracy:  0.99\n",
      "Epoch:  9 \tAccuracy:  1.0\n",
      "Test Accuracy:  0.9741\n",
      "done\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# parameters\n",
    "batch_size = 100\n",
    "learning_rate = 0.003\n",
    "training_epochs = 10\n",
    "\n",
    "# MNIST data set\n",
    "mnist = input_data.read_data_sets(\"./MNIST_DATA\", one_hot=True)\n",
    "\n",
    "# Network Layers\n",
    "L = 200\n",
    "M = 100\n",
    "N = 60\n",
    "O = 30\n",
    "\n",
    "# input\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "XX = tf.reshape(X, [-1, 784])\n",
    "\n",
    "# Layer1 (L=200)\n",
    "W1 = tf.Variable(tf.truncated_normal([784, L], stddev=0.1))\n",
    "B1 = tf.Variable(tf.zeros([L]))\n",
    "Y1 = tf.nn.relu(tf.matmul(XX, W1) + B1)\n",
    "\n",
    "# Layer2 (M=100)\n",
    "W2 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))\n",
    "B2 = tf.Variable(tf.zeros([M]))\n",
    "Y2 = tf.nn.relu(tf.matmul(Y1, W2) + B2)\n",
    "\n",
    "# Layer3 (N=60)\n",
    "W3 = tf.Variable(tf.truncated_normal([M, N], stddev=0.1))\n",
    "B3 = tf.Variable(tf.zeros([N]))\n",
    "Y3 = tf.nn.relu(tf.matmul(Y2, W3) + B3)\n",
    "\n",
    "# Layer4 (O=30)\n",
    "W4 = tf.Variable(tf.truncated_normal([N, O], stddev=0.1))\n",
    "B4 = tf.Variable(tf.zeros([O]))\n",
    "Y4 = tf.nn.relu(tf.matmul(Y3, W4) + B4)\n",
    "\n",
    "# Output Layer (Y=10)\n",
    "W5 = tf.Variable(tf.truncated_normal([O, 10], stddev=0.1))\n",
    "B5 = tf.Variable(tf.zeros([10]))\n",
    "Ylogits = tf.matmul(Y4, W5) + B5\n",
    "Y = tf.nn.softmax(Ylogits)\n",
    "\n",
    "# Loss function (Cross Entropy)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=Ylogits, labels=Y_)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)*100\n",
    "\n",
    "# Optimize (Adam)\n",
    "train_step = tf.train.AdamOptimizer(\n",
    "                learning_rate).minimize(cross_entropy)\n",
    "\n",
    "# accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(\n",
    "                tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train\n",
    "for epoch in range(training_epochs):\n",
    "    batch_count = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(batch_count):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, acc = sess.run([train_step, accuracy], \n",
    "                             feed_dict={X: batch_x,\n",
    "                                        Y_: batch_y})\n",
    "    print(\"Epoch: \", epoch, \"\\tAccuracy: \", acc)\n",
    "\n",
    "# test accuracy\n",
    "print(\"Test Accuracy: \", sess.run(accuracy,\n",
    "                            feed_dict={X: mnist.test.images,\n",
    "                                       Y_: mnist.test.labels}))\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_DATA\\train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_DATA\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_DATA\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_DATA\\t10k-labels-idx1-ubyte.gz\n",
      "Epoch:  0 \tAccuracy:  0.94\n",
      "Epoch:  1 \tAccuracy:  0.98\n",
      "Epoch:  2 \tAccuracy:  0.97\n",
      "Epoch:  3 \tAccuracy:  0.97\n",
      "Epoch:  4 \tAccuracy:  0.96\n",
      "Epoch:  5 \tAccuracy:  1.0\n",
      "Epoch:  6 \tAccuracy:  0.97\n",
      "Epoch:  7 \tAccuracy:  0.98\n",
      "Epoch:  8 \tAccuracy:  0.98\n",
      "Epoch:  9 \tAccuracy:  0.99\n",
      "Test Accuracy:  0.9776\n",
      "done\n",
      "Wall time: 37.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# parameters\n",
    "batch_size = 100\n",
    "learning_rate = 0.003\n",
    "training_epochs = 10\n",
    "\n",
    "# MNIST data set\n",
    "mnist = input_data.read_data_sets(\"./MNIST_DATA\", one_hot=True)\n",
    "\n",
    "# Network Layers\n",
    "L = 200\n",
    "M = 100\n",
    "N = 60\n",
    "O = 30\n",
    "\n",
    "# input\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "# dropout ration (0.75 => 75% data keep, 25% data dropout)\n",
    "dropout_ratio = tf.placeholder(tf.float32)\n",
    "\n",
    "XX = tf.reshape(X, [-1, 784])\n",
    "\n",
    "# Layer1 (L=200)\n",
    "W1 = tf.Variable(tf.truncated_normal([784, L], stddev=0.1))\n",
    "B1 = tf.Variable(tf.zeros([L]))\n",
    "Y1 = tf.nn.relu(tf.matmul(XX, W1) + B1)\n",
    "Y1d = tf.nn.dropout(Y1, dropout_ratio)\n",
    "\n",
    "# Layer2 (M=100)\n",
    "W2 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))\n",
    "B2 = tf.Variable(tf.zeros([M]))\n",
    "Y2 = tf.nn.relu(tf.matmul(Y1d, W2) + B2)\n",
    "Y2d = tf.nn.dropout(Y2, dropout_ratio)\n",
    "\n",
    "# Layer3 (N=60)\n",
    "W3 = tf.Variable(tf.truncated_normal([M, N], stddev=0.1))\n",
    "B3 = tf.Variable(tf.zeros([N]))\n",
    "Y3 = tf.nn.relu(tf.matmul(Y2d, W3) + B3)\n",
    "Y3d = tf.nn.dropout(Y3, dropout_ratio)\n",
    "\n",
    "# Layer4 (O=30)\n",
    "W4 = tf.Variable(tf.truncated_normal([N, O], stddev=0.1))\n",
    "B4 = tf.Variable(tf.zeros([O]))\n",
    "Y4 = tf.nn.relu(tf.matmul(Y3d, W4) + B4)\n",
    "Y4d = tf.nn.dropout(Y4, dropout_ratio)\n",
    "\n",
    "# Output Layer (Y=10)\n",
    "W5 = tf.Variable(tf.truncated_normal([O, 10], stddev=0.1))\n",
    "B5 = tf.Variable(tf.zeros([10]))\n",
    "Ylogits = tf.matmul(Y4, W5) + B5\n",
    "Y = tf.nn.softmax(Ylogits)\n",
    "\n",
    "# Loss function (Cross Entropy)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=Ylogits, labels=Y_)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)*100\n",
    "\n",
    "# Optimize (Adam)\n",
    "train_step = tf.train.AdamOptimizer(\n",
    "                learning_rate).minimize(cross_entropy)\n",
    "\n",
    "# accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(\n",
    "                tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train\n",
    "for epoch in range(training_epochs):\n",
    "    batch_count = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(batch_count):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, acc = sess.run([train_step, accuracy], \n",
    "                             feed_dict={X: batch_x,\n",
    "                                        Y_: batch_y,\n",
    "                                        dropout_ratio: 0.75})\n",
    "    print(\"Epoch: \", epoch, \"\\tAccuracy: \", acc)\n",
    "\n",
    "# test accuracy\n",
    "print(\"Test Accuracy: \", sess.run(accuracy,\n",
    "                            feed_dict={X: mnist.test.images,\n",
    "                                       Y_: mnist.test.labels,\n",
    "                                       dropout_ratio: 1.0}))\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
